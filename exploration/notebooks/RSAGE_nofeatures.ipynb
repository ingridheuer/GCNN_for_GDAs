{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RSAGE_nofeatures.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNQBmu8IXfEUZxLlHc+3adb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ingridheuer/GCNN_for_GDAs/blob/main/exploration/notebooks/RSAGE_nofeatures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalo e importo librerias"
      ],
      "metadata": {
        "id": "mdb7qExpc564"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "!pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "!pip install -q git+https://github.com/snap-stanford/deepsnap.git"
      ],
      "metadata": {
        "id": "GTfcOHHYtk9w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7721f95d-a656-434a-d9b3-01d5128a31d4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.11.0+cu113\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.11.0+cu113.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.7/dist-packages (2.0.9)\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.7/dist-packages (0.6.13)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0dg9JyPWqzOA"
      },
      "outputs": [],
      "source": [
        "#Librería base de redes neuronales de torch\n",
        "#Acá están las clases \"base\" de las que heredan todos los modelos\n",
        "import torch.nn as nn\n",
        "\n",
        "#Operaciones entre sparse matrix\n",
        "from torch_sparse import matmul, SparseTensor\n",
        "\n",
        "#Librerías específicas de GNNs: \n",
        "#PYG es la libraría general de GNNs,\n",
        "#DeepSNAP tiene utilidades para el manejo de datos y grafos heterogeneos, hacer splits, negative sampling, etc.\n",
        "import torch_geometric.nn as pyg_nn\n",
        "from torch_geometric.nn import HeteroConv\n",
        "from deepsnap.dataset import GraphDataset\n",
        "import deepsnap.hetero_gnn\n",
        "from deepsnap.hetero_gnn import forward_op\n",
        "from deepsnap.hetero_graph import HeteroGraph\n",
        "from torch_geometric.utils import to_undirected\n",
        "#from torch_geometric.data import HeteroData\n",
        "\n",
        "#Para manejar los minibatches\n",
        "from torch.utils.data import DataLoader\n",
        "from deepsnap.batch import Batch\n",
        "\n",
        "from timeit import default_timer as timer\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import copy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo"
      ],
      "metadata": {
        "id": "HU-IKGyKdD3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def edgeindex_to_sparsematrix(het_graph: HeteroGraph) -> dict : \n",
        "    sparse_edge_dict = {}\n",
        "    for key in het_graph.edge_index:\n",
        "        temp_edge_index = het_graph.edge_index[key]\n",
        "        from_type = key[0]\n",
        "        to_type = key[2]\n",
        "        adj = SparseTensor(row=temp_edge_index[0], col=temp_edge_index[1], sparse_sizes=(het_graph.num_nodes(from_type), het_graph.num_nodes(to_type)))\n",
        "        sparse_edge_dict[key] = adj.t()\n",
        "    return sparse_edge_dict\n",
        "\n",
        "# %%\n",
        "debugging = False\n",
        "\n",
        "def my_debug(arg):\n",
        "    if debugging:\n",
        "        print(arg)\n",
        "#%%\n",
        "#OLD DICT STYLE\n",
        "class HeteroGNNConv(pyg_nn.MessagePassing):\n",
        "    def __init__(self, in_channels_src, in_channels_dst, out_channels):\n",
        "        super().__init__(aggr=\"mean\")\n",
        "\n",
        "        self.in_channels_src = in_channels_src\n",
        "        self.in_channels_dst = in_channels_dst\n",
        "        self.out_channels = out_channels\n",
        "        self.lin_dst = torch.nn.Linear(in_channels_dst, out_channels)\n",
        "        self.lin_src = torch.nn.Linear(in_channels_src, out_channels)\n",
        "        self.lin_update = torch.nn.Linear(2*out_channels, out_channels)\n",
        "\n",
        "    def forward(\n",
        "            self,\n",
        "            node_feature_src,\n",
        "            node_feature_dst,\n",
        "            edge_index,\n",
        "            size=None):\n",
        "\n",
        "        out = self.propagate(\n",
        "            edge_index, size, node_feature_src=node_feature_src, node_feature_dst=node_feature_dst)\n",
        "        return out\n",
        "\n",
        "    def message_and_aggregate(self, edge_index, node_feature_src):\n",
        "        out = matmul(edge_index, node_feature_src, reduce=self.aggr)\n",
        "        #my_debug(f'message_and_agregate out: {out}')\n",
        "\n",
        "        return out\n",
        "\n",
        "    def update(self, aggr_out, node_feature_dst):\n",
        "\n",
        "        dst_msg = self.lin_dst(node_feature_dst)\n",
        "        src_msg = self.lin_src(aggr_out)\n",
        "        full_msg = torch.concat((dst_msg, src_msg), dim=1)\n",
        "        out = self.lin_update(full_msg)\n",
        "        #my_debug(f'update out: {out}')\n",
        "        return out\n",
        "\n",
        "\n",
        "class HeteroGNNWrapperConv(deepsnap.hetero_gnn.HeteroConv):\n",
        "    def __init__(self, convs, args, aggr=\"mean\"):\n",
        "        super().__init__(convs, None)\n",
        "        self.aggr = aggr\n",
        "\n",
        "        # Map the index and message type\n",
        "        self.mapping = {}\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        super().reset_parameters()\n",
        "\n",
        "    def forward(self, node_features, edge_indices):\n",
        "        message_type_emb = {}\n",
        "        #my_debug(f'Wrapper self convs: {self.convs}')\n",
        "        for message_key, message_type in edge_indices.items():\n",
        "            src_type, edge_type, dst_type = message_key\n",
        "            # my_debug(message_key)\n",
        "            # my_debug(node_features.shape)\n",
        "            #my_debug(f\"Input x shape: {node_features.shape}\")\n",
        "            #my_debug(f'Wrapper self conv step: {self.convs[message_key]}')\n",
        "            node_feature_src = node_features[src_type]\n",
        "            node_feature_dst = node_features[dst_type]\n",
        "            edge_index = edge_indices[message_key]\n",
        "            #my_debug(f'Wrapper message_type_emb step: {self.convs[message_key](node_feature_src,node_feature_dst,edge_index)}')\n",
        "            message_type_emb[message_key] = (\n",
        "                self.convs[message_key](\n",
        "                    node_feature_src,\n",
        "                    node_feature_dst,\n",
        "                    edge_index,\n",
        "                )\n",
        "            )\n",
        "            #my_debug(f'{message_key} emb done: {message_type_emb}')\n",
        "        node_emb = {dst: [] for _, _, dst in message_type_emb.keys()}\n",
        "        #my_debug(f'node emb: {node_emb}')\n",
        "        mapping = {}\n",
        "        for (src, edge_type, dst), item in message_type_emb.items():\n",
        "            mapping[len(node_emb[dst])] = (src, edge_type, dst)\n",
        "            node_emb[dst].append(item)\n",
        "        self.mapping = mapping\n",
        "        for node_type, embs in node_emb.items():\n",
        "            if len(embs) == 1:\n",
        "                node_emb[node_type] = embs[0]\n",
        "            else:\n",
        "                node_emb[node_type] = self.aggregate(embs)\n",
        "        #my_debug(f'node_emb from wrapper conv forward:{node_emb}')\n",
        "        return node_emb\n",
        "\n",
        "    def aggregate(self, xs):\n",
        "        return torch.mean(torch.stack(xs), dim=0)\n",
        "\n",
        "\n",
        "def generate_convs(hetero_graph, conv, hidden_size, first_layer=False):\n",
        "    convs = {}\n",
        "\n",
        "    msg_types = hetero_graph.message_types\n",
        "    for key in msg_types:\n",
        "        if first_layer:\n",
        "            dst_feature_dim = hetero_graph.num_node_features(key[2])\n",
        "            src_feature_dim = hetero_graph.num_node_features(key[0])\n",
        "            convs[key] = conv(src_feature_dim, dst_feature_dim, hidden_size)\n",
        "        else:\n",
        "            convs[key] = conv(hidden_size, hidden_size, hidden_size)\n",
        "\n",
        "    return convs\n",
        "\n",
        "\n",
        "class HeteroGNN(torch.nn.Module):\n",
        "    def __init__(self, hetero_graph_dict, args, aggr=\"mean\"):\n",
        "        super().__init__()\n",
        "\n",
        "        hetero_graph = hetero_graph_dict[\"graph\"]\n",
        "        self.aggr = aggr\n",
        "        self.hidden_size = args['hidden_size']\n",
        "        self.bns1 = torch.nn.ModuleDict()\n",
        "        self.bns2 = torch.nn.ModuleDict()\n",
        "        self.relus1 = torch.nn.ModuleDict()\n",
        "        self.relus2 = torch.nn.ModuleDict()\n",
        "        self.loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "        #self.post_mps = nn.ModuleDict()\n",
        "\n",
        "        convs1 = generate_convs(hetero_graph, HeteroGNNConv, self.hidden_size, first_layer=True)\n",
        "        #my_debug(f'convs1: {convs1}')\n",
        "        convs2 = generate_convs(hetero_graph, HeteroGNNConv, self.hidden_size, first_layer=False)\n",
        "        self.convs1 = HeteroGNNWrapperConv(convs1, args, aggr=self.aggr)\n",
        "        #my_debug(f'self.convs1: {self.convs1}')\n",
        "        self.convs2 = HeteroGNNWrapperConv(convs2, args, aggr=self.aggr)\n",
        "        for node_type in hetero_graph.node_types:\n",
        "            self.bns1[node_type] = torch.nn.BatchNorm1d(self.hidden_size)\n",
        "            self.bns2[node_type] = torch.nn.BatchNorm1d(self.hidden_size)\n",
        "            self.relus1[node_type] = torch.nn.LeakyReLU()\n",
        "            self.relus2[node_type] = torch.nn.LeakyReLU()\n",
        "\n",
        "    def forward(self, graph_dict):\n",
        "        #x, adj, edge_label_index = graph_dict[\"graph\"].node_feature, graph_dict[\"adj\"], graph_dict[\"graph\"].edge_label_index\n",
        "        x,edge_label_index = graph_dict[\"graph\"].node_feature, graph_dict[\"graph\"].edge_label_index\n",
        "        adj = edgeindex_to_sparsematrix(graph_dict[\"graph\"])\n",
        "        x = self.convs1(x, edge_indices=adj)\n",
        "        x = deepsnap.hetero_gnn.forward_op(x, self.bns1)\n",
        "        x = deepsnap.hetero_gnn.forward_op(x, self.relus1)\n",
        "        x = self.convs2(x, edge_indices=adj)\n",
        "        x = deepsnap.hetero_gnn.forward_op(x, self.bns2)\n",
        "        #my_debug(f\"Output x shape: {x.shape}\")\n",
        "        x = deepsnap.hetero_gnn.forward_op(x, self.relus2)\n",
        "        #x = forward_op(x, self.post_mps)\n",
        "\n",
        "        pred = {}\n",
        "        for message_type in edge_label_index:\n",
        "            my_debug(f\"{len(edge_label_index[message_type][0])}\")\n",
        "            src_type = message_type[0]\n",
        "            trg_type = message_type[2]\n",
        "            nodes_first = torch.index_select(x[src_type], 0, edge_label_index[message_type][0,:].long())\n",
        "            nodes_second = torch.index_select(x[trg_type], 0, edge_label_index[message_type][1,:].long())\n",
        "            my_debug(f\"Multiplying shapes {nodes_first.shape}, {nodes_second.shape}\")\n",
        "            pred[message_type] = torch.sum(nodes_first * nodes_second, dim=-1)\n",
        "            my_debug(f\"Pred shape {pred[message_type].shape}\")\n",
        "        return pred\n",
        "\n",
        "    def loss(self, pred, y):\n",
        "        loss = 0\n",
        "        for key in pred:\n",
        "            p = torch.sigmoid(pred[key])\n",
        "            loss += self.loss_fn(p, y[key].type(pred[key].dtype))\n",
        "        return loss"
      ],
      "metadata": {
        "id": "QqVw_uB4ryT0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocesamiento del dataset"
      ],
      "metadata": {
        "id": "ECs63Gy2dIT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "node_data = pd.read_csv(\"/content/graph_node_table.csv\", index_col=0)\n",
        "edge_data = pd.read_csv(\"/content/graph_edge_table.csv\",index_col=0).rename(columns={\"relation\":\"edge_type\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkRxNATbrZXz",
        "outputId": "a8489120-9bf3-4d3b-9c6b-254dcdb14b31"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (4,5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "D = nx.from_pandas_edgelist(edge_data,source=\"a_idx\",target=\"b_idx\", edge_attr=\"edge_type\", create_using=nx.DiGraph)\n",
        "nx.set_node_attributes(D,pd.Series(node_data.node_type, index=node_data.node_idx).to_dict(),\"node_type\")\n",
        "nx.set_node_attributes(D,pd.Series(node_data.node_name, index=node_data.node_idx).to_dict(),\"node_name\")\n",
        "\n",
        "#G = nx.to_undirected(D)\n",
        "G = D\n",
        "\n",
        "node_id = 5\n",
        "print(f\"Node {node_id} has properties:\", G.nodes(data=True)[node_id])\n",
        "# %%\n",
        "edges = list(G.edges())\n",
        "edge_idx = 123456\n",
        "n1 = edges[edge_idx][0]\n",
        "n2 = edges[edge_idx][1]\n",
        "edge = list(G.edges(data=True))[edge_idx]\n",
        "print(f\"Edge ({edge[0]}, {edge[1]}) has properties:\", edge[2])\n",
        "print(f\"Node {n1} has properties:\", G.nodes(data=True)[n1])\n",
        "print(f\"Node {n2} has properties:\", G.nodes(data=True)[n2])\n",
        "#%%\n",
        "G_deepsnap = HeteroGraph(G)\n",
        "G_deepsnap.edge_types\n",
        "G_deepsnap.message_types\n",
        "G_deepsnap.node_types\n",
        "G_deepsnap.num_nodes()\n",
        "G_deepsnap.num_edges()\n",
        "list(G.edges(data=True))[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSYIXytLrkD5",
        "outputId": "46e03440-9f31-4284-cba1-4cf9692351fb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node 5 has properties: {'node_type': 'gene/protein', 'node_name': 'SERPINA3'}\n",
            "Edge (4873, 15076) has properties: {'edge_type': 'GDA'}\n",
            "Node 4873 has properties: {'node_type': 'gene/protein', 'node_name': 'IQSEC1'}\n",
            "Node 15076 has properties: {'node_type': 'disease', 'node_name': 'Short stature'}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1839, 14989, {'edge_type': 'GDA'})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "node_feature = torch.ones(5)\n",
        "nx.set_node_attributes(G, node_feature, 'node_feature')\n",
        "hete = HeteroGraph(G)\n",
        "task = 'link_pred'\n",
        "dataset = GraphDataset([hete], task=task, edge_train_mode=\"all\")\n",
        "dataset_train, dataset_val, dataset_test = dataset.split(transductive=True, split_ratio=[0.4, 0.3, 0.3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asQoc7HSr3Wu",
        "outputId": "a3634075-a9d9-400e-835e-778ac4cc96ec"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/deepsnap/hetero_graph.py:3142: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  col[message_type] = perm[message_type] // num_nodes[head_type]\n",
            "/usr/local/lib/python3.7/dist-packages/deepsnap/hetero_graph.py:3138: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  row[message_type] = perm[message_type] // num_nodes[tail_type]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Funciones de entrenamiento y evaluación"
      ],
      "metadata": {
        "id": "4xtdovjbdN36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, graph_dict, printb):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    preds = model(graph_dict)\n",
        "    loss = model.loss(preds, graph_dict[\"graph\"].edge_label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if printb:\n",
        "        print(loss.item())\n",
        "    return loss.item()\n",
        "\n",
        "\n",
        "# Test function\n",
        "def test(model, graph_dict, args):\n",
        "    model.eval()\n",
        "    accs = {}\n",
        "    for mode, dataset in graph_dict.items():\n",
        "        acc = 0\n",
        "        num = 0\n",
        "        pred = model(dataset)\n",
        "        for key in pred:\n",
        "            p = torch.sigmoid(pred[key]).cpu().detach().numpy()\n",
        "            pred_label = np.zeros_like(p, dtype=np.int64)\n",
        "            pred_label[np.where(p > 0.5)[0]] = 1\n",
        "            pred_label[np.where(p <= 0.5)[0]] = 0\n",
        "            acc += np.sum(pred_label == dataset[\"graph\"].edge_label[key].cpu().numpy())\n",
        "            num += len(pred_label)\n",
        "        accs[mode] = acc / num\n",
        "    return accs\n"
      ],
      "metadata": {
        "id": "j4Y6Ixugr0tj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenamiento"
      ],
      "metadata": {
        "id": "bg0Wm9reditL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = {\n",
        "    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
        "    'hidden_size': 32,\n",
        "    'weight_decay': 1e-5,\n",
        "    'lr': 0.003,\n",
        "}\n",
        "\n",
        "datasets = {\"train\":dataset_train, \"val\":dataset_val, \"test\":dataset_test}\n",
        "sparse_dict = {title:{\"graph\":dataset[0].to(args[\"device\"]), \"adj\":[]} for title,dataset in datasets.items()}\n",
        "fullgraph_sparse_dict = {\"graph\":hete, \"adj\":[]}\n",
        "\n",
        "model = HeteroGNN(fullgraph_sparse_dict, args, aggr=\"mean\").to(args[\"device\"])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])"
      ],
      "metadata": {
        "id": "beTv40jSr_SJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28a25ab6-531e-45df-a672-6ef6f18f840f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/deepsnap/hetero_graph.py:3142: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  col[message_type] = perm[message_type] // num_nodes[head_type]\n",
            "/usr/local/lib/python3.7/dist-packages/deepsnap/hetero_graph.py:3138: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  row[message_type] = perm[message_type] // num_nodes[tail_type]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61kYn4i_Zpue",
        "outputId": "d2aed461-8991-4e18-fe3d-d8b51f91e7c0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroGNN(\n",
              "  (bns1): ModuleDict(\n",
              "    (gene/protein): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (disease): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (protein_complex): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (bns2): ModuleDict(\n",
              "    (gene/protein): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (disease): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (protein_complex): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (relus1): ModuleDict(\n",
              "    (gene/protein): LeakyReLU(negative_slope=0.01)\n",
              "    (disease): LeakyReLU(negative_slope=0.01)\n",
              "    (protein_complex): LeakyReLU(negative_slope=0.01)\n",
              "  )\n",
              "  (relus2): ModuleDict(\n",
              "    (gene/protein): LeakyReLU(negative_slope=0.01)\n",
              "    (disease): LeakyReLU(negative_slope=0.01)\n",
              "    (protein_complex): LeakyReLU(negative_slope=0.01)\n",
              "  )\n",
              "  (loss_fn): BCEWithLogitsLoss()\n",
              "  (convs1): HeteroGNNWrapperConv(\n",
              "    (modules): ModuleList(\n",
              "      (0): HeteroGNNConv()\n",
              "      (1): HeteroGNNConv()\n",
              "      (2): HeteroGNNConv()\n",
              "      (3): HeteroGNNConv()\n",
              "    )\n",
              "  )\n",
              "  (convs2): HeteroGNNWrapperConv(\n",
              "    (modules): ModuleList(\n",
              "      (0): HeteroGNNConv()\n",
              "      (1): HeteroGNNConv()\n",
              "      (2): HeteroGNNConv()\n",
              "      (3): HeteroGNNConv()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_plot = []\n",
        "epochs = 2000\n",
        "for epoch in range(epochs):\n",
        "    if epoch%10 == 0:\n",
        "       loss = train(model,optimizer,sparse_dict[\"train\"],printb=True)\n",
        "    else:\n",
        "        loss = train(model,optimizer,sparse_dict[\"train\"],printb=False)\n",
        "    loss_plot.append(loss)\n",
        "\n",
        "plt.plot(np.arange(len(loss_plot)),loss_plot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "enAuSbO9sB-r",
        "outputId": "ce9dbd10-2f7b-4a72-a802-afcc9ea328f0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.142920970916748\n",
            "2.955369710922241\n",
            "2.8683598041534424\n",
            "2.8561649322509766\n",
            "2.85170316696167\n",
            "2.849128007888794\n",
            "2.8462040424346924\n",
            "2.8436973094940186\n",
            "2.8411848545074463\n",
            "2.8389668464660645\n",
            "2.836660861968994\n",
            "2.8342134952545166\n",
            "2.8314638137817383\n",
            "2.82920503616333\n",
            "2.8265910148620605\n",
            "2.8238422870635986\n",
            "2.821122407913208\n",
            "2.818341016769409\n",
            "2.8156137466430664\n",
            "2.8126869201660156\n",
            "2.809678792953491\n",
            "2.8067221641540527\n",
            "2.8036134243011475\n",
            "2.800494909286499\n",
            "2.797459602355957\n",
            "2.7943553924560547\n",
            "2.791100025177002\n",
            "2.7878284454345703\n",
            "2.7838354110717773\n",
            "2.7798280715942383\n",
            "2.7765989303588867\n",
            "2.7732510566711426\n",
            "2.770289659500122\n",
            "2.766963243484497\n",
            "2.7636094093322754\n",
            "2.760321855545044\n",
            "2.7570395469665527\n",
            "2.7540647983551025\n",
            "2.750687837600708\n",
            "2.7474594116210938\n",
            "2.7442448139190674\n",
            "2.7411715984344482\n",
            "2.738152027130127\n",
            "2.7352757453918457\n",
            "2.7321951389312744\n",
            "2.729226589202881\n",
            "2.726356029510498\n",
            "2.7234904766082764\n",
            "2.720677614212036\n",
            "2.717956304550171\n",
            "2.7154531478881836\n",
            "2.712733745574951\n",
            "2.7102246284484863\n",
            "2.7077643871307373\n",
            "2.7053258419036865\n",
            "2.7028799057006836\n",
            "2.700566291809082\n",
            "2.698422908782959\n",
            "2.696298837661743\n",
            "2.6940884590148926\n",
            "2.6919665336608887\n",
            "2.689980983734131\n",
            "2.6880242824554443\n",
            "2.6861777305603027\n",
            "2.684347152709961\n",
            "2.6825079917907715\n",
            "2.680629253387451\n",
            "2.6790404319763184\n",
            "2.6775453090667725\n",
            "2.6758534908294678\n",
            "2.674330949783325\n",
            "2.672844886779785\n",
            "2.671285629272461\n",
            "2.6699485778808594\n",
            "2.6686220169067383\n",
            "2.667274236679077\n",
            "2.665891170501709\n",
            "2.6646111011505127\n",
            "2.6634457111358643\n",
            "2.6620919704437256\n",
            "2.6610586643218994\n",
            "2.6600279808044434\n",
            "2.658848762512207\n",
            "2.6576905250549316\n",
            "2.656721830368042\n",
            "2.655428886413574\n",
            "2.6541748046875\n",
            "2.6532609462738037\n",
            "2.6524107456207275\n",
            "2.6514883041381836\n",
            "2.650646686553955\n",
            "2.6496338844299316\n",
            "2.6487631797790527\n",
            "2.6478168964385986\n",
            "2.647040605545044\n",
            "2.6461620330810547\n",
            "2.6454296112060547\n",
            "2.6447298526763916\n",
            "2.6439177989959717\n",
            "2.6433115005493164\n",
            "2.642505645751953\n",
            "2.641939878463745\n",
            "2.641310214996338\n",
            "2.640516757965088\n",
            "2.6398653984069824\n",
            "2.6392734050750732\n",
            "2.6386232376098633\n",
            "2.638212203979492\n",
            "2.637606620788574\n",
            "2.6370744705200195\n",
            "2.636388063430786\n",
            "2.6360106468200684\n",
            "2.635340690612793\n",
            "2.6348538398742676\n",
            "2.6343462467193604\n",
            "2.633978843688965\n",
            "2.6333937644958496\n",
            "2.632951259613037\n",
            "2.632520914077759\n",
            "2.63204288482666\n",
            "2.6317079067230225\n",
            "2.631223440170288\n",
            "2.630861282348633\n",
            "2.630500078201294\n",
            "2.6301169395446777\n",
            "2.6296846866607666\n",
            "2.6293368339538574\n",
            "2.628931999206543\n",
            "2.628554344177246\n",
            "2.6282804012298584\n",
            "2.627880334854126\n",
            "2.6275107860565186\n",
            "2.627211093902588\n",
            "2.626864433288574\n",
            "2.626664638519287\n",
            "2.626300811767578\n",
            "2.6260297298431396\n",
            "2.6256988048553467\n",
            "2.6255316734313965\n",
            "2.625204563140869\n",
            "2.6249613761901855\n",
            "2.6246275901794434\n",
            "2.624427318572998\n",
            "2.6241061687469482\n",
            "2.6238741874694824\n",
            "2.6235828399658203\n",
            "2.623373508453369\n",
            "2.6231112480163574\n",
            "2.6229677200317383\n",
            "2.622753858566284\n",
            "2.622502326965332\n",
            "2.6222455501556396\n",
            "2.6220157146453857\n",
            "2.621819019317627\n",
            "2.6215662956237793\n",
            "2.6214182376861572\n",
            "2.6211912631988525\n",
            "2.620980978012085\n",
            "2.620786428451538\n",
            "2.6205787658691406\n",
            "2.6204142570495605\n",
            "2.62033748626709\n",
            "2.6201400756835938\n",
            "2.6201534271240234\n",
            "2.619860887527466\n",
            "2.6197166442871094\n",
            "2.619523763656616\n",
            "2.6193110942840576\n",
            "2.6190671920776367\n",
            "2.619013547897339\n",
            "2.6188125610351562\n",
            "2.6185975074768066\n",
            "2.6184768676757812\n",
            "2.6183724403381348\n",
            "2.61818528175354\n",
            "2.6180286407470703\n",
            "2.617924213409424\n",
            "2.6177425384521484\n",
            "2.617584228515625\n",
            "2.617319345474243\n",
            "2.61715030670166\n",
            "2.616802930831909\n",
            "2.61674427986145\n",
            "2.616968870162964\n",
            "2.616952419281006\n",
            "2.616429328918457\n",
            "2.616461753845215\n",
            "2.6165761947631836\n",
            "2.6163668632507324\n",
            "2.615968704223633\n",
            "2.6159534454345703\n",
            "2.6157281398773193\n",
            "2.615553140640259\n",
            "2.620420455932617\n",
            "2.617900848388672\n",
            "2.6175663471221924\n",
            "2.616856575012207\n",
            "2.6162545680999756\n",
            "2.6157448291778564\n",
            "2.6154699325561523\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe785add790>]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = model(sparse_dict[\"val\"])\n",
        "prediction = {edgetype:torch.round(torch.sigmoid(pred)) for edgetype,pred in p.items()}\n",
        "ground_truth = dataset_val[0].edge_label\n",
        "\n",
        "test(model,sparse_dict,args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZN1kLFUsG1G",
        "outputId": "678e7aaf-dd8b-431d-fc1b-73759afe57a2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test': 0.6604004393848611,\n",
              " 'train': 0.7115044330640102,\n",
              " 'val': 0.6716266992897}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}